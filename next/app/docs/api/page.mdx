# API Reference

## API Access

Most API routes require an **access token** as part of the _Authorization_ request header.

```http
Authorization: Bearer <access_token>
```

Valid access token depend on the configured providers. For command line use
generate an API token on the `Settings` page.

Access tokens have different scopes, the required scopes are documented for each API call.
API calls that do not require scopes are available without an Authorization header.

**Scopes:**

- `upload`: these tokens are only valid for data upload, they are used for the ingress feature.
- `api`: these tokens are valid for all API calls that do not require admin permission.
- `admin`: these tokens are valid for all API calls.
- `download`: tokens with this scope are generated on demand an only valid for downloading a single dataset.

## GET `api/v1/healthy`

**Required Scopes:** _none_

Used for the API server health check. Always returns

```json
{ "ok": true }
```

## POST `/admin/key/confirm`

**Required Scopes:** _admin_

**Request Body**:

```json
  "keyId": "<number | the numeric id of the key>"
  "confirmed": "<boolean | the new state of the key>"
```

**Description:**
Set the status of a public key. If the `confirmed` state is false the key cannot be used.
Only _admins_ can confirm keys

**Response:** `ok`

## GET `/admin/dataset/orphan`

**Required Scopes:** _admin_

**Response:**
List of orphaned datasets, datasets with no valid non-root keys.

```json
{
    "id": "<number | numeric data set id>",
    "mnemonic": "<string | dataset mnemonic id>",
    "name": "<string | dataset tag>",
    "fileName": "<string | the file name of the dataset>",
    "path": "<string/null | the origial path of the file",
    "hash": "<string | the hash of the dataset>",
    "size": "<number | the size of the dataset, in bytes>",
    "keyHash": "<string | the fingerprint of the AES key>",
    "createdBy": "<the id of the user who uploaded the dataset>",
    "validated": "<string | timestamp of last validation>",
    "createdAt": "<string | creation timestamp>",
    "updatedAt": "<string | timestamp of last change",
    "deletedAt": "<string/null | if not null the timestamp when the dataset was removed",
    "members": [{
        "permission": "<string | permission level>",
        "sub": "<string | user id>"
    },...]
},

```

## GET `/admin/events`

**Required Scopes:** _admin_

**Description:**
List all days on which events occured.

**Response:**

```json
["<YYYY-MM-DD>", ...]
```

## GET `/admin/events/:date`

**Required Scopes:** _admin_

**Parameters:**

- date: the day for which to list events

**Description:**
List all documented events in the event history.

**Response:**

```json
{
    "id": "<number | unique event id>",
    "sub": "<string | the user ID that generated the event>",
    "mnemonic": "<string/null | the id of the dataset the event applies to>",
    "event": "<string | event name>",
    "message": "<string | event message>",
    "day": "<string | the day the event occured>",
    "createdAt": "<string | the full event timestamp>",
}, ...
```

## GET `/upload/check`

**Required Scopes**: _upload_

**Description:**
Check if an incomplete upload exists.

**Response:**
`null` if no incomplete upload exists. Else return the incomplete dataset:

```json
{
    "id": "<number | numeric data set id>",
    "mnemonic": "<string | dataset mnemonic id>",
    "name": "<string | dataset tag>",
    "fileName": "<string | the file name of the dataset>",
    "path": "<string/null | the origial path of the file",
    "hash": "<string | the hash of the dataset>",
    "size": "<number | the size of the dataset, in bytes>",
    "keyHash": "<string | the fingerprint of the AES key>",
    "createdBy": "<the id of the user who uploaded the dataset>",
    "validated": "<string | timestamp of last validation>",
    "createdAt": "<string | creation timestamp>",
    "updatedAt": "<string | timestamp of last change",
    "deletedAt": "<string/null | if not null the timestamp when the dataset was removed",
    "chunks": [{
      "id": "<number | numeric chunk id>",
      "hash": "SHA-256 hash of the chunk",
      "iv": "<AES initialization vector>",
      "start": "<number | byte positon of the start of the chunk>",
      "end": "<number | byte positon of the end of the chunk>",
      "size": "<number | total size of the dataset>",
    },...]
}
```

## POST `/upload/start`

**Required Scopes**: _upload_

**Description:** Start a new upload.

**Request Body:**

```json
  {
    "name":"<string, optional | the name tag for the upload>"
    "fileName":"<string | the name of the file to upload>"
    "path":"<string, optional | the origial path of the file>"
    "size":"<number, optional | the full size of the file >"
    "chunkHash":"<string, optional | the base64 hash of the first chunk of the file>"
  }
```

**Response:**
Returns the newly created dataset, with a new mnemonic.

```json
{
  "id": "<number | numeric data set id>",
  "mnemonic": "<string | dataset mnemonic id>",
  "name": "<string | dataset tag>",
  "fileName": "<string | the file name of the dataset>",
  "path": "<string/null | the origial path of the file",
  "hash": "<string | the hash of the dataset>",
  "size": "<number | the size of the dataset, in bytes>",
  "keyHash": "<string | the fingerprint of the AES key>",
  "createdBy": "<the id of the user who uploaded the dataset>",
  "validated": "<string | timestamp of last validation>",
  "createdAt": "<string | creation timestamp>",
  "updatedAt": "<string | timestamp of last change",
  "deletedAt": "<string/null | if not null the timestamp when the dataset was removed",
  "duplicate": "<string/null | if the dataset is a duplicate the full hash of the existing dataset>"
}
```

## PUT `/upload/:mnemonic`

**Required Scopes**: _upload_

**Description:**
Add a new chunk of data to the upload **mnemonic**
Chunks may be sent in parallel, and out of order.

**Request:**

**Note:** this request has type `multipart/form-data` instead of `application/json`, because this is the
standard way to upload files.

**Request Headers:**

- `Digest`: `sha-256=<chunk hash>`
- `Content-Range`: `bytes <chunk start>-<chunk end>/<file size>`
- `Content-Type`: 'multipart/form-data'

**Form data:**
attach the chunk data, with any file name.

**Response:**
Returns the newly created or existing chunk.

```json
{
  "id": "<number | numeric chunk id>",
  "hash": "SHA-256 hash of the chunk",
  "iv": "<AES initialization vector>",
  "start": "<number | byte positon of the start of the chunk>",
  "end": "<number | byte positon of the end of the chunk>",
  "size": "<number | total size of the dataset>"
}
```

## POST `/upload/finish/:mnemonic`

**Required Scopes**: _upload_

**Parameters:**

- mnemonic: the ID of the dataset

**Description:**
Complete an upload, send the request after all chunks
requests completed successfully.

**Response:**

Returns the full hash of the dataset, calculated form all the chunk hashes.
If chunks are missing, will return an error.

```json
{
  "hash": "<string | the hash of the dataset>"
}
```

## POST `/upload/cancel/:mnemonic`

**Required Scopes**: _upload_

**Parameters:**

- mnemonic: the ID of the dataset

**Description:**
Cancel the upload for the mnemonic.
Remove all the data that was uploaded already.

## POST `/dataset/:mnemonic/download`

**Required Scopes**: _api_

**Parameters:**

- mnemonic: the ID of the dataset

**Request Body:**

```json
{
  "key": "<string | the base64 encoded AES key for the dataset>"
}
```

Generate a download token for a dataset.
This will store the AES key of the dataset in the servers ephemeral storage
and enable downloading using server decryption.

**Response Body:**
The access token used to download the dataset, only valid for 10 seconds and
only for a single dataset.

```json
{
  "token": "<string | the access token for the dataset download>"
}
```

## GET `/:mnemonic/download`

**Use the special access token generated from `/dataset/:mnemonic/download`
in the Authorization Header**

Required Scopes: _download_

**Parameters:**

- mnemonic: the ID of the dataset

**Description:**

Download the decrypted dataset

**Response:**

Responds with the decrypted dataset as an attachment.

## POST `/dataset/search`

**Required Scopes**: _api_

**Description:**
Search for datasets using a query, includes fuzzy matching.

**Request Body:**

```json
{
  "query": "<string/null | search string>",
  "uploader": "<boolean/null | return only dataset uploaded by the user>",
  "page": "<integer | return the nth page of results>",
  "limit": "<string/null | limit the amount of results>",
  "column": "<string/null | sort the results with this key>",
  "direction": "<string /null|DESC(default) or ASC>",
  "deleted": "<boolean | (admin only) also return deleted datasets>",
  "all": "<boolean | (admin only) return all datasets, also those where the user is not a member>"
}
```

**Response:**
Returns a list of dataset and a total count of datasets matching the query.

```json
{
  "count": <number | number of datasets that match the query>
  "datasets":[
    {
      "id": "<number | numeric data set id>",
      "mnemonic": "<string | dataset mnemonic id>",
      "name": "<string | dataset tag>",
      "fileName": "<string | the file name of the dataset>",
      "permission": "<string | the permission the user has on the dataset>",
      "path": "<string/null | the origial path of the file",
      "hash": "<string | the hash of the dataset>",
      "size": "<number | the size of the dataset, in bytes>",
      "keyHash": "<string | the fingerprint of the AES key>",
      "createdBy": "<the id of the user who uploaded the dataset>",
      "validated": "<string | timestamp of last validation>",
      "createdAt": "<string | creation timestamp>",
      "updatedAt": "<string | timestamp of last change",
      "deletedAt": "<string/null | if not null the timestamp when the dataset was removed",
      "members": [{
          "permission": "<string | permission level>",
          "sub": "<string | user id>"
      },...]
    }, ...
  ]
}
```

## POST `/dataset/find`

**Required Scopes**: _api_

**Request Body:**

```json
{
  "mnemonic": "<string/null | match on the mnemonic>"
  "name": "<string/null | match the dataset tag>",
  "fileName": "<string/null | the file name of the dataset>",
  "hash": "<string/null | the hash of the dataset>",
  ...
}
```

**Description:**
Find datasets using one of their keys. Only exact matches will be returned.

**Response:**
Returns a list of datasets matching the query key.
Only returns datasets the user has access to.
Will return removed datasets.

```json
{
  "datasets":[
    {
      "id": "<number | numeric data set id>",
      "mnemonic": "<string | dataset mnemonic id>",
      "name": "<string | dataset tag>",
      "fileName": "<string | the file name of the dataset>",
      "permission": "<string | the permission the user has on the dataset>",
      "path": "<string/null | the origial path of the file",
      "hash": "<string | the hash of the dataset>",
      "size": "<number | the size of the dataset, in bytes>",
      "keyHash": "<string | the fingerprint of the AES key>",
      "createdBy": "<the id of the user who uploaded the dataset>",
      "validated": "<string | timestamp of last validation>",
      "createdAt": "<string | creation timestamp>",
      "updatedAt": "<string | timestamp of last change",
      "deletedAt": "<string/null | if not null the timestamp when the dataset was removed",
      "members": [{
          "permission": "<string | permission level>",
          "sub": "<string | user id>"
      },...]
    }, ...
  ]
}
```

## GET `/dataset/:mnemonic`

**Required Scopes**: _api_

**Parameters:**

- mnemonic: the ID of the dataset

**Description:**
Return dataset information and chunks.

**Response:**

```json
{
    "id": "<number | numeric data set id>",
    "mnemonic": "<string | dataset mnemonic id>",
    "name": "<string | dataset tag>",
    "fileName": "<string | the file name of the dataset>",
    "path": "<string/null | the origial path of the file",
    "hash": "<string | the hash of the dataset>",
    "size": "<number | the size of the dataset, in bytes>",
    "keyHash": "<string | the fingerprint of the AES key>",
    "createdBy": "<the id of the user who uploaded the dataset>",
    "validated": "<string | timestamp of last validation>",
    "createdAt": "<string | creation timestamp>",
    "updatedAt": "<string | timestamp of last change",
    "deletedAt": "<string/null | if not null the timestamp when the dataset was removed",
    "chunks": [{
      "id": "<number | numeric chunk id>",
      "hash": "SHA-256 hash of the chunk",
      "iv": "<AES initialization vector>",
      "start": "<number | byte positon of the start of the chunk>",
      "end": "<number | byte positon of the end of the chunk>",
      "size": "<number | total size of the dataset>",
    },...]
}
```

## GET `/dataset/:mnemonic/chunk/:chunkHash`

**Required Scopes**: _api_

**Parameters:**

- mnemonic: the ID of the dataset
- chunkHash: the base64url encoded SHA-256 hash of the chunk

**Description:**

Return the encrypted chunk of with the hash `chunkHash` from
the dataset `mnemonic`

**Response:**
Chunk data, as an attachment.

## POST `/dataset/:mnemonic/remove`

**Required Scopes**: _api_

**Parameters:**

- mnemonic: the ID of the dataset

**Description:**
Remove a dataset, this is a soft deletion and is reversible.

## POST `/dataset/:mnemonic/recover`

**Required Scopes**: _admin_

**Parameters:**

- mnemonic: the ID of the dataset

**Description:**
Recover a removed dataset, this will undo removal.

## POST `/dataset/:mnemonic/destroy`

**Required Scopes**: _api_

**Parameters:**

- mnemonic: the ID of the dataset

**Description:**
Permanently remove the dataset, it cannot be recovered.
Only dataset that have been deleted for 24h can be destroyed.
Admins may destroy datasets immediately.

## POST `/dataset/:mnemonic/member/add`

**Required Scopes**: _api_

**Parameters:**

- mnemonic: the ID of the dataset

**Description:**
Add a new member to the dataset, this will trigger re-encryption of the AES key.

## POST `/dataset/:mnemonic/member/set`

**Required Scopes**: _api_

**Parameters:**

- mnemonic: the ID of the dataset

**Description:**
Set the permission for a member of the dataset.

## POST `/dataset/:mnemonic/reencrypt`

**Required Scopes**: _api_

**Parameters:**

- mnemonic: the ID of the dataset

**Description:**
Re-encrypt the dataset, this will replace the symmetric AES key.

## POST `/dataset/:mnemonic/rename`

**Required Scopes**: _api_

**Parameters:**

- mnemonic: the ID of the dataset

**Description:**
Set the name tag for the dataset.

## GET `/key/list`

**Required Scopes**: _api_

## POST `/key/add`

**Required Scopes**: _api_

## POST `/key/check`

**Required Scopes**: _api_

## POST `/key/remove`

**Required Scopes**: _api_

## POST `/token`

**Required Scopes**: _api_

## POST `/token/generate/:type`

**Required Scopes**: _api_

## GET `/token/list`

**Required Scopes**: _api_

## POST `/token/remove`

**Required Scopes**: _api_

```

```
